{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextSuggestionSystem.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnE7gUqkxU0Q"
      },
      "source": [
        "import nltk\r\n",
        "from collections import Counter, defaultdict"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-sAwlIpGJNB"
      },
      "source": [
        "# Preparing Corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gC6aDmnTGRR-"
      },
      "source": [
        "def getReutersSentences():\r\n",
        "  nltk.download('reuters')\r\n",
        "  nltk.download('punkt')\r\n",
        "  from nltk.corpus import reuters\r\n",
        "  return reuters.sents()\r\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1WZqB50HwiI"
      },
      "source": [
        "def getWikiSentenes():\r\n",
        "  from gensim.test.utils import datapath\r\n",
        "  from gensim.corpora import WikiCorpus\r\n",
        "  path_to_wiki_dump = datapath(\"enwiki-latest-pages-articles1.xml-p000000010p000030302-shortened.bz2\")\r\n",
        "  wiki=WikiCorpus(path_to_wiki_dump)\r\n",
        "  return wiki.get_texts()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XY6GuJ48IKfv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "736e9cfa-eccb-42ef-bd69-3a6f1d1c6f30"
      },
      "source": [
        "'''\r\n",
        "Combine all sentences\r\n",
        "'''\r\n",
        "\r\n",
        "reutersSentences=getReutersSentences()\r\n",
        "wikiSentences=getWikiSentenes()\r\n",
        "\r\n",
        "sentencesCorpus=[]\r\n",
        "\r\n",
        "for s in wikiSentences:\r\n",
        "  sentencesCorpus.append(s)\r\n",
        "\r\n",
        "for s in reutersSentences:\r\n",
        "  sentencesCorpus.append(s)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]   Package reuters is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbXMDwr1rELK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe7079cb-c70d-41ba-dc72-a681d1bdd910"
      },
      "source": [
        "print(len(reutersSentences))\r\n",
        "print(len(sentencesCorpus))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "54716\n",
            "54822\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mK4jh3CUOcCk"
      },
      "source": [
        "# Naive Bayes Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wErScvesw5Ru"
      },
      "source": [
        "'''\r\n",
        "Modeling Naive Bayes\r\n",
        "'''\r\n",
        "class NaiveBayes:\r\n",
        "  def __init__(self):\r\n",
        "    pass\r\n",
        "  \r\n",
        "  def tryToLower(self,u):\r\n",
        "    if type(u)==str:\r\n",
        "      return u.lower()\r\n",
        "    return u\r\n",
        "\r\n",
        "  def countWordFrequency(self):\r\n",
        "    self.wordCount=0\r\n",
        "    self.wordFrequency = defaultdict(lambda: 0)\r\n",
        "    for sentence in self.sentences:\r\n",
        "      for word in sentence:\r\n",
        "        word=self.tryToLower(word)\r\n",
        "        self.wordFrequency[word]+=1\r\n",
        "        self.wordCount+=1\r\n",
        "\r\n",
        "  def countBigramFrequency(self):\r\n",
        "    from nltk import bigrams\r\n",
        "    self.bigramFrequency = defaultdict(lambda: defaultdict(lambda: 0))\r\n",
        "    self.nextWords = defaultdict(lambda: set())\r\n",
        "\r\n",
        "    for sentence in self.sentences:\r\n",
        "      for wPrev, wCurrent in bigrams(sentence, pad_right=True, pad_left=True):\r\n",
        "        wCurrent=self.tryToLower(wCurrent)\r\n",
        "        wPrev=self.tryToLower(wPrev)\r\n",
        "        self.bigramFrequency[wCurrent][wPrev]+=1\r\n",
        "        self.nextWords[wPrev].add(wCurrent)\r\n",
        "\r\n",
        "  def countTrigramFrequency(self):\r\n",
        "    from nltk import trigrams\r\n",
        "    self.bigramFrequency = defaultdict(lambda: defaultdict(lambda: 0))\r\n",
        "    self.partialTrigramFrequency = defaultdict(lambda: defaultdict(lambda: 0))\r\n",
        "    self.nextWords = defaultdict(lambda: set())\r\n",
        "    self.secondNextWords = defaultdict(lambda: set())\r\n",
        "\r\n",
        "    for sentence in  self.sentences:\r\n",
        "      for wPrev2, wPrev1, wCurrent in trigrams(sentence, pad_right=True, pad_left=True):\r\n",
        "          wPrev2=self.tryToLower(wPrev2)\r\n",
        "          wPrev1=self.tryToLower(wPrev1)\r\n",
        "          wCurrent=self.tryToLower(wCurrent)\r\n",
        "          self.bigramFrequency[wCurrent][wPrev1] += 1 # number of times w2 is previous word when w3 is current word\r\n",
        "          self.partialTrigramFrequency[wCurrent][wPrev2] += 1 # number of times w1 is 2nd previous word when w3 is current word\r\n",
        "          self.nextWords[wPrev1].add(wCurrent)\r\n",
        "          self.secondNextWords[wPrev2].add(wCurrent)\r\n",
        "    \r\n",
        "  def calculateConditionalProbablities(self,model):\r\n",
        "    for wCurrent in model:\r\n",
        "      total_count = float(sum(model[wCurrent].values()))\r\n",
        "      for wPrev in model[wCurrent]:\r\n",
        "        model[wCurrent][wPrev] /= total_count\r\n",
        "\r\n",
        "  def calculateProbablity(self):\r\n",
        "    for word in self.wordFrequency:\r\n",
        "      self.wordFrequency[word] /=self.wordCount\r\n",
        "  \r\n",
        "  def calculateNaiveBayesBigram(self,wPrev,wCurrent):\r\n",
        "    return self.wordFrequency[wCurrent]*self.bigramFrequency[wCurrent][wPrev]\r\n",
        "   \r\n",
        "  def calculateNaiveBayesTrigram(self,wPrev2,wPrev1,wCurrent):\r\n",
        "    return self.wordFrequency[wCurrent]*self.bigramFrequency[wCurrent][wPrev1]* self.partialTrigramFrequency[wCurrent][wPrev2]\r\n",
        "\r\n",
        "  def trainGivenWord(self,corpus):\r\n",
        "    self.sentences=corpus\r\n",
        "\r\n",
        "    self.countWordFrequency()\r\n",
        "    self.countBigramFrequency()\r\n",
        "    self.calculateConditionalProbablities(self.bigramFrequency)\r\n",
        "    self.calculateProbablity()\r\n",
        "  \r\n",
        "  def trainGiven2Word(self,corpus):\r\n",
        "    self.sentences=corpus\r\n",
        "    \r\n",
        "    self.countWordFrequency()\r\n",
        "    self.countTrigramFrequency()\r\n",
        "    self.calculateConditionalProbablities(self.bigramFrequency)\r\n",
        "    self.calculateConditionalProbablities(self.partialTrigramFrequency)\r\n",
        "    self.calculateProbablity()\r\n",
        "\r\n",
        "  def predictGivenOneWord(self,words=[]):\r\n",
        "    wPrev=words[0]\r\n",
        "    self.givenWords=[wPrev]\r\n",
        "    self.predictions=[]\r\n",
        "    for wNext in self.nextWords[wPrev]:\r\n",
        "      sc=self.calculateNaiveBayesBigram(wPrev,wNext)\r\n",
        "      self.predictions.append((wNext,sc))\r\n",
        "    self.predictions.sort(key=lambda o: o[1],reverse=True)\r\n",
        "    return self.predictions;\r\n",
        "  \r\n",
        "  def predictGiven2Word(self,words=[]):\r\n",
        "    wP2,wP1=words\r\n",
        "    self.givenWords=[wP2,wP1]\r\n",
        "    self.predictions=[]\r\n",
        "    for wNext in self.nextWords[wP1] & self.secondNextWords[wP2]:\r\n",
        "      sc=self.calculateNaiveBayesTrigram(wP2,wP1,wNext)\r\n",
        "      self.predictions.append((wNext,sc))\r\n",
        "    self.predictions.sort(key=lambda o: o[1],reverse=True)\r\n",
        "    return self.predictions\r\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FD6Sgfy3OSrs"
      },
      "source": [
        "# Applying Naive Bayes on Corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMhVUYHeEsVR",
        "outputId": "a17f1f5b-aa53-442f-9f26-ae5ea709f794"
      },
      "source": [
        "'''\r\n",
        "Applying Naive bayes given One word \r\n",
        "'''\r\n",
        "TestData=['is']\r\n",
        "nbOneWordModel=NaiveBayes()\r\n",
        "nbOneWordModel.trainGivenWord(sentencesCorpus)\r\n",
        "secondWords=nbOneWordModel.predictGivenOneWord(TestData)\r\n",
        "secondWords[:10]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 0.00042183009861256076),\n",
              " ('not', 0.00023920572658509443),\n",
              " ('expected', 0.00023552563848378528),\n",
              " ('a', 0.00019642470240737562),\n",
              " ('also', 0.00012006287430521087),\n",
              " ('to', 0.00011592277519123807),\n",
              " ('an', 9.614230164670142e-05),\n",
              " ('in', 9.384224658338319e-05),\n",
              " ('likely', 8.234197126679214e-05),\n",
              " ('still', 8.050192721613755e-05)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUgGUJJNF5u-",
        "outputId": "0228c272-49c0-42c9-b06a-b93814613839"
      },
      "source": [
        "'''\r\n",
        "Applying Naive bayes given Two word \r\n",
        "'''\r\n",
        "TestData=['is','the']\r\n",
        "\r\n",
        "nbTwoWordModel=NaiveBayes()\r\n",
        "nbTwoWordModel.trainGiven2Word(sentencesCorpus)\r\n",
        "thirdWords=nbTwoWordModel.predictGiven2Word(TestData)\r\n",
        "thirdWords[:10]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('first', 1.1230247545308053e-05),\n",
              " ('largest', 8.776546244970887e-06),\n",
              " ('most', 4.957163150812947e-06),\n",
              " ('world', 4.237934309173298e-06),\n",
              " ('second', 3.834429935177943e-06),\n",
              " ('main', 3.771881682067424e-06),\n",
              " ('only', 3.625161413229904e-06),\n",
              " ('possibility', 3.206242170971408e-06),\n",
              " ('same', 2.886704401821027e-06),\n",
              " ('oldest', 2.6943502170299097e-06)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_usdxQzfYV5"
      },
      "source": [
        "# Model Evaluation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZJNVoVtyxD-",
        "outputId": "23ae3200-03f6-4c79-9ba9-a239a97d2079"
      },
      "source": [
        "!pip install language_tool_python"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: language_tool_python in /usr/local/lib/python3.6/dist-packages (2.5.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from language_tool_python) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from language_tool_python) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->language_tool_python) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->language_tool_python) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->language_tool_python) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->language_tool_python) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxS3V9S_yITS"
      },
      "source": [
        " import language_tool_python\r\n",
        " class NaiveBayesModelEvaluation:\r\n",
        "  def __init__(self): \r\n",
        "     self.tool = language_tool_python.LanguageTool('en-US')\r\n",
        "  \r\n",
        "  def checkGrammaticalMistakes(self,words=[]):\r\n",
        "    '''\r\n",
        "    Setting up python language tool to check grammer \r\n",
        "    '''\r\n",
        "    text = ' '.join(words)  \r\n",
        "    matches = self.tool.check(text)\r\n",
        "    return len(matches)-1\r\n",
        "  \r\n",
        "  def score(self,model,top=100):\r\n",
        "    topPredctions=model.predictions[:top]\r\n",
        "    total=len(topPredctions)\r\n",
        "    correct=0\r\n",
        "    for pWord in topPredctions:\r\n",
        "      if self.checkGrammaticalMistakes(model.givenWords+[pWord[0]])==0:\r\n",
        "        correct+=1\r\n",
        "  \r\n",
        "    return (correct/total)*100\r\n",
        "\r\n",
        "modelEval= NaiveBayesModelEvaluation()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JA8D-68elNrS",
        "outputId": "d8afd5d4-5714-450e-8b09-35e90318cb3c"
      },
      "source": [
        "'''\r\n",
        "got score 99.0 for top 100 when given one word\r\n",
        "\r\n",
        "Function Defination :\r\n",
        "  nb.score(top=20) -> top = best 20 suggestions \r\n",
        "'''\r\n",
        "\r\n",
        "print(modelEval.score(nbOneWordModel,top=30))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlAUBqVWnEqz",
        "outputId": "8a36626e-a533-4b2e-9573-4f9ee8beb112"
      },
      "source": [
        "'''\r\n",
        "got score 97.0 for top 100 when given two word less than given one word because naive bayes' independance property\r\n",
        "\r\n",
        "Function Defination :\r\n",
        "  nbt.score(top=20) -> top = best 20 suggestions\r\n",
        "'''\r\n",
        "print(modelEval.score(nbTwoWordModel,top=30))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "97.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}