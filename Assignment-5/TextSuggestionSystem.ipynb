{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TextSuggestionSystem.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNfu6Rf5ymXvI0fAiwCCVcZ"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"cnE7gUqkxU0Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610638777057,"user_tz":-360,"elapsed":7375,"user":{"displayName":"Uttom Akash","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-04OT2wgqJ1LmG8yPpeQT3zwJrPQM8X9cgbSU=s64","userId":"05479479216842369208"}},"outputId":"2d43544e-7e4e-4981-f979-bdb94c3d5405"},"source":["!pip install language_tool_python\r\n","import nltk\r\n","from collections import Counter, defaultdict\r\n","import language_tool_python"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting language_tool_python\n","  Downloading https://files.pythonhosted.org/packages/49/81/945fec190c623cd3f08860216fd1a107541677b742fa2df4a9b8fc6c4b24/language_tool_python-2.5.1-py3-none-any.whl\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from language_tool_python) (2.23.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from language_tool_python) (4.41.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->language_tool_python) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->language_tool_python) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->language_tool_python) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->language_tool_python) (3.0.4)\n","Installing collected packages: language-tool-python\n","Successfully installed language-tool-python-2.5.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"b-sAwlIpGJNB"},"source":["# Preparing Corpus"]},{"cell_type":"code","metadata":{"id":"gC6aDmnTGRR-","executionInfo":{"status":"ok","timestamp":1610638777067,"user_tz":-360,"elapsed":7348,"user":{"displayName":"Uttom Akash","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-04OT2wgqJ1LmG8yPpeQT3zwJrPQM8X9cgbSU=s64","userId":"05479479216842369208"}}},"source":["def getReutersSentences():\r\n","  nltk.download('reuters')\r\n","  nltk.download('punkt')\r\n","  from nltk.corpus import reuters\r\n","  return reuters.sents()\r\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cg_qdm0mqAPu","executionInfo":{"status":"ok","timestamp":1610638777071,"user_tz":-360,"elapsed":7317,"user":{"displayName":"Uttom Akash","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-04OT2wgqJ1LmG8yPpeQT3zwJrPQM8X9cgbSU=s64","userId":"05479479216842369208"}}},"source":["def getBrownSentences():\r\n","  nltk.download('brown')\r\n","  from nltk.corpus import brown\r\n","  return brown.sents()"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"w1WZqB50HwiI","executionInfo":{"status":"ok","timestamp":1610638777073,"user_tz":-360,"elapsed":7308,"user":{"displayName":"Uttom Akash","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-04OT2wgqJ1LmG8yPpeQT3zwJrPQM8X9cgbSU=s64","userId":"05479479216842369208"}}},"source":["def getWikiSentenes():\r\n","  from gensim.test.utils import datapath\r\n","  from gensim.corpora import WikiCorpus\r\n","  path_to_wiki_dump = datapath(\"enwiki-latest-pages-articles1.xml-p000000010p000030302-shortened.bz2\")\r\n","  wiki=WikiCorpus(path_to_wiki_dump)\r\n","  return wiki.get_texts()"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"XY6GuJ48IKfv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610638799278,"user_tz":-360,"elapsed":29501,"user":{"displayName":"Uttom Akash","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-04OT2wgqJ1LmG8yPpeQT3zwJrPQM8X9cgbSU=s64","userId":"05479479216842369208"}},"outputId":"9e8308da-4f27-47ea-8cd8-700b016e39ec"},"source":["'''\r\n","Combine all sentences\r\n","'''\r\n","\r\n","reutersSentences=getReutersSentences()\r\n","# brownSentences=getBrownSentences()\r\n","wikiSentences=getWikiSentenes()\r\n","\r\n","sentencesCorpus=[]\r\n","\r\n","for s in wikiSentences:\r\n","  sentencesCorpus.append(s)\r\n","\r\n","for s in reutersSentences:\r\n","  sentencesCorpus.append(s)\r\n","\r\n","# for s in brownSentences:\r\n","#   sentencesCorpus.append(s)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package reuters to /root/nltk_data...\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KbXMDwr1rELK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610638799282,"user_tz":-360,"elapsed":29497,"user":{"displayName":"Uttom Akash","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-04OT2wgqJ1LmG8yPpeQT3zwJrPQM8X9cgbSU=s64","userId":"05479479216842369208"}},"outputId":"0f855fa1-8ffb-4cf9-d5ea-fc5a44dd08e2"},"source":["print(len(reutersSentences))\r\n","print(len(sentencesCorpus))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["54716\n","54822\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mK4jh3CUOcCk"},"source":["# Naive Bayes Model"]},{"cell_type":"code","metadata":{"id":"wErScvesw5Ru","executionInfo":{"status":"ok","timestamp":1610638799283,"user_tz":-360,"elapsed":29490,"user":{"displayName":"Uttom Akash","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-04OT2wgqJ1LmG8yPpeQT3zwJrPQM8X9cgbSU=s64","userId":"05479479216842369208"}}},"source":["'''\r\n","Modeling Naive Bayes\r\n","'''\r\n","class NaiveBayes:\r\n","  def __init__(self):\r\n","    self.tool = language_tool_python.LanguageTool('en-US')\r\n","  \r\n","  def tryToLower(self,u):\r\n","    if type(u)==str:\r\n","      return u.lower()\r\n","    return u\r\n","\r\n","  def countWordFrequency(self):\r\n","    self.wordCount=0\r\n","    self.wordFrequency = defaultdict(lambda: 0)\r\n","    for sentence in self.sentences:\r\n","      for word in sentence:\r\n","        word=self.tryToLower(word)\r\n","        self.wordFrequency[word]+=1\r\n","        self.wordCount+=1\r\n","\r\n","  def countBigramFrequency(self):\r\n","    from nltk import bigrams\r\n","    self.bigramFrequency = defaultdict(lambda: defaultdict(lambda: 0))\r\n","    self.nextWords = defaultdict(lambda: set())\r\n","\r\n","    for sentence in self.sentences:\r\n","      for wPrev, wCurrent in bigrams(sentence, pad_right=True, pad_left=True):\r\n","        wCurrent=self.tryToLower(wCurrent)\r\n","        wPrev=self.tryToLower(wPrev)\r\n","        self.bigramFrequency[wCurrent][wPrev]+=1\r\n","        self.nextWords[wPrev].add(wCurrent)\r\n","\r\n","  def countTrigramFrequency(self):\r\n","    from nltk import trigrams\r\n","    self.bigramFrequency = defaultdict(lambda: defaultdict(lambda: 0))\r\n","    self.partialTrigramFrequency = defaultdict(lambda: defaultdict(lambda: 0))\r\n","    self.nextWords = defaultdict(lambda: set())\r\n","    self.secondNextWords = defaultdict(lambda: set())\r\n","\r\n","    for sentence in  self.sentences:\r\n","      for wPrev2, wPrev1, wCurrent in trigrams(sentence, pad_right=True, pad_left=True):\r\n","          wPrev2=self.tryToLower(wPrev2)\r\n","          wPrev1=self.tryToLower(wPrev1)\r\n","          wCurrent=self.tryToLower(wCurrent)\r\n","          self.bigramFrequency[wCurrent][wPrev1] += 1 # number of times w2 is previous word when w3 is current word\r\n","          self.partialTrigramFrequency[wCurrent][wPrev2] += 1 # number of times w1 is 2nd previous word when w3 is current word\r\n","          self.nextWords[wPrev1].add(wCurrent)\r\n","          self.secondNextWords[wPrev2].add(wCurrent)\r\n","    \r\n","  def calculateConditionalProbablities(self,model):\r\n","    for wCurrent in model:\r\n","      total_count = float(sum(model[wCurrent].values()))\r\n","      for wPrev in model[wCurrent]:\r\n","        model[wCurrent][wPrev] /= total_count\r\n","\r\n","  def calculateProbablity(self):\r\n","    for word in self.wordFrequency:\r\n","      self.wordFrequency[word] /=self.wordCount\r\n","  \r\n","  def calculateNaiveBayesBigram(self,wPrev,wCurrent):\r\n","    return self.wordFrequency[wCurrent]*self.bigramFrequency[wCurrent][wPrev]\r\n","   \r\n","  def calculateNaiveBayesTrigram(self,wPrev2,wPrev1,wCurrent):\r\n","    return self.wordFrequency[wCurrent]*self.bigramFrequency[wCurrent][wPrev1]* self.partialTrigramFrequency[wCurrent][wPrev2]\r\n","\r\n","  def trainGivenWord(self,corpus):\r\n","    self.sentences=corpus\r\n","\r\n","    self.countWordFrequency()\r\n","    self.countBigramFrequency()\r\n","    self.calculateConditionalProbablities(self.bigramFrequency)\r\n","    self.calculateProbablity()\r\n","  \r\n","  def trainGiven2Word(self,corpus):\r\n","    self.sentences=corpus\r\n","    \r\n","    self.countWordFrequency()\r\n","    self.countTrigramFrequency()\r\n","    self.calculateConditionalProbablities(self.bigramFrequency)\r\n","    self.calculateConditionalProbablities(self.partialTrigramFrequency)\r\n","    self.calculateProbablity()\r\n","\r\n","  def predictGivenOneWord(self,words=[]):\r\n","    wPrev=words[0]\r\n","    self.givenWords=[wPrev]\r\n","    self.predictions=[]\r\n","    for wNext in self.nextWords[wPrev]:\r\n","      sc=self.calculateNaiveBayesBigram(wPrev,wNext)\r\n","      self.predictions.append((wNext,sc))\r\n","    self.predictions.sort(key=lambda o: o[1],reverse=True)\r\n","    return self.predictions;\r\n","  \r\n","  def predictGiven2Word(self,words=[]):\r\n","    wP2,wP1=words\r\n","    self.givenWords=[wP2,wP1]\r\n","    self.predictions=[]\r\n","    for wNext in self.nextWords[wP1] & self.secondNextWords[wP2]:\r\n","      sc=self.calculateNaiveBayesTrigram(wP2,wP1,wNext)\r\n","      self.predictions.append((wNext,sc))\r\n","    self.predictions.sort(key=lambda o: o[1],reverse=True)\r\n","    return self.predictions\r\n","  \r\n","  def checkGrammaticalMistakes(self,words=[]):\r\n","    '''\r\n","    Setting up python language tool to check grammer \r\n","    '''\r\n","    text = ' '.join(words)  \r\n","    matches = self.tool.check(text)\r\n","    return len(matches)-1\r\n","  \r\n","  def score(self,top=100):\r\n","    topPredctions=self.predictions[:top]\r\n","    total=len(topPredctions)\r\n","    correct=0\r\n","    for pWord in topPredctions:\r\n","      if self.checkGrammaticalMistakes(self.givenWords+[pWord[0]])==0:\r\n","        correct+=1\r\n","  \r\n","    return (correct/total)*100 \r\n","  \r\n"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FD6Sgfy3OSrs"},"source":["# Applying Naive Bayes on Corpus"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tMhVUYHeEsVR","executionInfo":{"status":"ok","timestamp":1610638816661,"user_tz":-360,"elapsed":46859,"user":{"displayName":"Uttom Akash","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-04OT2wgqJ1LmG8yPpeQT3zwJrPQM8X9cgbSU=s64","userId":"05479479216842369208"}},"outputId":"05fa3b59-8839-4d71-c503-cec91e93d4ab"},"source":["'''\r\n","Applying Naive bayes given One word \r\n","'''\r\n","TestData=['is']\r\n","nb=NaiveBayes()\r\n","nb.trainGivenWord(sentencesCorpus)\r\n","secondWords=nb.predictGivenOneWord(TestData)\r\n","secondWords[:10]"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Downloading LanguageTool: 100%|██████████| 190M/190M [00:10<00:00, 18.7MB/s]\n","Unzipping /tmp/tmpunwdqbn_.zip to /root/.cache/language_tool_python.\n","Downloaded https://www.languagetool.org/download/LanguageTool-5.2.zip to /root/.cache/language_tool_python.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["[('the', 0.00042183009861256076),\n"," ('not', 0.00023920572658509443),\n"," ('expected', 0.00023552563848378528),\n"," ('a', 0.00019642470240737562),\n"," ('also', 0.00012006287430521087),\n"," ('to', 0.00011592277519123807),\n"," ('an', 9.614230164670142e-05),\n"," ('in', 9.384224658338319e-05),\n"," ('likely', 8.234197126679214e-05),\n"," ('still', 8.050192721613755e-05)]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sUgGUJJNF5u-","executionInfo":{"status":"ok","timestamp":1610638833178,"user_tz":-360,"elapsed":63366,"user":{"displayName":"Uttom Akash","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-04OT2wgqJ1LmG8yPpeQT3zwJrPQM8X9cgbSU=s64","userId":"05479479216842369208"}},"outputId":"1eb3023f-e324-4da2-b1fd-a19134239d1f"},"source":["'''\r\n","Applying Naive bayes given Two word \r\n","'''\r\n","TestData=['is','the']\r\n","\r\n","nbt=NaiveBayes()\r\n","nbt.trainGiven2Word(sentencesCorpus)\r\n","thirdWords=nbt.predictGiven2Word(TestData)\r\n","thirdWords[:10]"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('first', 1.1230247545308053e-05),\n"," ('largest', 8.776546244970887e-06),\n"," ('most', 4.957163150812947e-06),\n"," ('world', 4.237934309173298e-06),\n"," ('second', 3.834429935177943e-06),\n"," ('main', 3.771881682067424e-06),\n"," ('only', 3.625161413229904e-06),\n"," ('possibility', 3.206242170971408e-06),\n"," ('same', 2.886704401821027e-06),\n"," ('oldest', 2.6943502170299097e-06)]"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"0_usdxQzfYV5"},"source":["# Model Evaluation "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JA8D-68elNrS","executionInfo":{"status":"ok","timestamp":1610638942483,"user_tz":-360,"elapsed":4095,"user":{"displayName":"Uttom Akash","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-04OT2wgqJ1LmG8yPpeQT3zwJrPQM8X9cgbSU=s64","userId":"05479479216842369208"}},"outputId":"ad879099-3757-4e67-fad1-b5a04ed83623"},"source":["'''\r\n","got score 99.0 for top 100 when given one word\r\n","\r\n","Function Defination :\r\n","  nb.score(top=20) -> top = best 20 suggestions \r\n","'''\r\n","\r\n","print(nb.score(top=30))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["100.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tlAUBqVWnEqz","executionInfo":{"status":"ok","timestamp":1610638948093,"user_tz":-360,"elapsed":4670,"user":{"displayName":"Uttom Akash","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-04OT2wgqJ1LmG8yPpeQT3zwJrPQM8X9cgbSU=s64","userId":"05479479216842369208"}},"outputId":"6ad09fab-4e9e-4ed3-9442-7f90b87c6a71"},"source":["'''\r\n","got score 97.0 for top 100 when given two word less than given one word because naive bayes' independance property\r\n","\r\n","Function Defination :\r\n","  nbt.score(top=20) -> top = best 20 suggestions\r\n","'''\r\n","print(nbt.score(top=30))"],"execution_count":13,"outputs":[{"output_type":"stream","text":["100.0\n"],"name":"stdout"}]}]}